"""Module for Regression Testing the InVEST Coastal Vulnerability module."""
import unittest
import tempfile
import shutil
import os
import pickle
import json

from osgeo import gdal, osr, ogr
import numpy.testing
import pandas.testing
import pygeoprocessing
from pygeoprocessing.testing import sampledata
from shapely.geometry import Point, Polygon, MultiPolygon, LineString, MultiLineString
import shapely.wkb
import taskgraph

from natcap.invest import coastal_vulnerability

REGRESSION_DATA = os.path.join(
    os.path.dirname(__file__), '..', 'data', 'invest-test-data',
    'coastal_vulnerability')
INPUT_DATA = os.path.join(
    os.path.dirname(__file__), '..', 'data', 'invest-test-data',
    'coastal_vulnerability', 'input')


class CoastalVulnerabilityTests(unittest.TestCase):
    """Tests for the Coastal Vulnerability Model."""

    def setUp(self):
        """Overriding setUp function to create temp workspace directory."""
        # this lets us delete the workspace after its done no matter the
        # the test result
        self.workspace_dir = tempfile.mkdtemp()

    def tearDown(self):
        """Overriding tearDown function to remove temporary directory."""
        shutil.rmtree(self.workspace_dir)

    @staticmethod
    def generate_base_args(workspace_dir):
        """Generate an args dict with default required args."""
        args = {'workspace_dir': workspace_dir,
                'n_workers': -1,
                'wwiii_vector_path': os.path.join(
                    INPUT_DATA, 'WaveWatchIII_subset.shp'),
                'landmass_vector_path': os.path.join(
                    INPUT_DATA, 'land_polygon_simple_utm.shp'),
                'aoi_vector_path': os.path.join(
                    INPUT_DATA, 'AOI_BarkClay.shp'),
                'model_resolution': 25000,
                'max_fetch_distance': 12000,
                'dem_path': os.path.join(
                    INPUT_DATA, 'dem_wgs84.tif'),
                'dem_averaging_radius': 33000.0,
                'bathymetry_raster_path': os.path.join(
                    INPUT_DATA, 'dem_wgs84.tif'),
                'habitat_table_path': os.path.join(
                    INPUT_DATA, "natural_habitats_wcvi.csv"),
                'shelf_contour_vector_path': os.path.join(
                    INPUT_DATA, 'continental_shelf_contour.gpkg')
                }
        return args

    def test_wind_and_wave_exposure(self):
        """CV: regression test for wind and wave exposure values.

        The wave calculation depends on an intermediate product from
        the wind calculation, so I'm testing them both in this scope.

        """
        workspace_dir = self.workspace_dir
        # these points have the WWIII values interpolated onto them.
        base_shore_point_vector_path = os.path.join(
            INPUT_DATA, "wwiii_shore_points_5000m.gpkg")
        max_fetch_distance = 12000
        target_fetch_point_vector_path = os.path.join(
            workspace_dir, 'fetch_points.gpkg')
        target_fetch_rays_vector_path = os.path.join(
            workspace_dir, 'fetch_rays.gpkg')
        target_wind_exposure_pickle_path = os.path.join(
            workspace_dir, 'wind.pickle')

        landmass_vector_path = os.path.join(
            INPUT_DATA, 'land_polygon_simple_utm.shp')
        landmass_polygon_pickle_path = os.path.join(
            workspace_dir, 'polygon.pickle')
        landmass_lines_pickle_path = os.path.join(
            workspace_dir, 'lines.pickle')
        landmass_lines_rtree_path = os.path.join(
            workspace_dir, 'lines_rtree.dat')

        base_bathy_raster_path = os.path.join(INPUT_DATA, 'dem_wgs84.tif')
        target_bathy_raster_path = os.path.join(
            workspace_dir, 'negative_bathymetry.tif')
        aoi_vector_info = pygeoprocessing.get_vector_info(
            base_shore_point_vector_path)
        aoi_srs_wkt = aoi_vector_info['projection']
        aoi_bounding_box = aoi_vector_info['bounding_box']
        # add the max_fetch_distance to the bounding box so we can use
        # the clipped raster in the fetch-ray-depth routine.
        model_resolution = 5000
        fetch_buffer = max_fetch_distance + model_resolution  # add the model resolution, to be safe
        aoi_bounding_box[0] -= fetch_buffer
        aoi_bounding_box[1] -= fetch_buffer
        aoi_bounding_box[2] += fetch_buffer
        aoi_bounding_box[3] += fetch_buffer

        coastal_vulnerability.warp_and_mask_bathymetry(
            base_bathy_raster_path, aoi_srs_wkt, aoi_bounding_box,
            model_resolution, workspace_dir, '',
            target_bathy_raster_path)

        coastal_vulnerability.prepare_landmass_line_index(
            landmass_vector_path, landmass_polygon_pickle_path,
            landmass_lines_pickle_path, landmass_lines_rtree_path)

        coastal_vulnerability.calculate_wind_exposure(
            base_shore_point_vector_path,
            landmass_polygon_pickle_path,
            landmass_lines_rtree_path,
            landmass_lines_pickle_path,
            target_bathy_raster_path,
            target_fetch_rays_vector_path,
            max_fetch_distance,
            target_fetch_point_vector_path,
            target_wind_exposure_pickle_path)

        expected_raw_values_path = os.path.join(
            REGRESSION_DATA, 'expected_wind.json')
        assert_pickled_arrays_almost_equal(
            target_wind_exposure_pickle_path, expected_raw_values_path)

        target_wave_exposure_pickle_path = os.path.join(
            workspace_dir, 'wave.pickle')
        coastal_vulnerability.calculate_wave_exposure(
            target_fetch_point_vector_path, max_fetch_distance,
            os.path.join(workspace_dir, 'intermediate_wave.gpkg'),
            target_wave_exposure_pickle_path)

        expected_raw_values_path = os.path.join(
            REGRESSION_DATA, 'expected_wave.json')
        assert_pickled_arrays_almost_equal(
            target_wave_exposure_pickle_path, expected_raw_values_path)

    def test_extract_bathymetry(self):
        """CV: regression test for extracting bathymetry along ray."""
        # Make a simple raster
        raster_path = os.path.join(self.workspace_dir, 'foo.tif')
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N
        projection_wkt = srs.ExportToWkt()
        geotransform = [0, 1.0, 0.0, 0, 0.0, -1.0]
        n = 5
        nodata_val = 9999
        gtiff_driver = gdal.GetDriverByName('GTiff')
        new_raster = gtiff_driver.Create(
            raster_path, n, n, 2, gdal.GDT_Int32, options=[
                'TILED=YES', 'BIGTIFF=YES', 'COMPRESS=LZW',
                'BLOCKXSIZE=16', 'BLOCKYSIZE=16'])
        new_raster.SetProjection(projection_wkt)
        new_raster.SetGeoTransform(geotransform)
        array = numpy.array([-1]*n*n).reshape((n, n))

        # nodata across the top row for Band 1
        new_band = new_raster.GetRasterBand(1)
        array[:1] = nodata_val
        new_band.WriteArray(array)
        new_band.SetNoDataValue(nodata_val)

        # all nodata for Band 2
        nodata_band = new_raster.GetRasterBand(2)
        array[:] = nodata_val
        nodata_band.WriteArray(array)
        nodata_band.SetNoDataValue(nodata_val)

        new_raster.FlushCache()
        new_band = None
        nodata_band = None
        new_raster = None

        # Ray is only over valid pixels
        all_valid_ray = ogr.Geometry(ogr.wkbLineString)
        all_valid_ray.AddPoint(0, -2)
        all_valid_ray.AddPoint(3, -4)

        # Ray is over some valid and some nodata pixels
        some_nodata_ray = ogr.Geometry(ogr.wkbLineString)
        some_nodata_ray.AddPoint(0, 0)
        some_nodata_ray.AddPoint(4, -4)

        # Ray is only over nodata pixels,
        # so the final extract window will be expanded as needed
        all_nodata_ray = ogr.Geometry(ogr.wkbLineString)
        all_nodata_ray.AddPoint(-0.5, 0.5)
        all_nodata_ray.AddPoint(3.5, 0.5)

        # Ray is partially outside the bounds of the raster
        out_of_bounds_ray = ogr.Geometry(ogr.wkbLineString)
        out_of_bounds_ray.AddPoint(3, -3)
        out_of_bounds_ray.AddPoint(3, -7)

        raster = gdal.OpenEx(raster_path, gdal.OF_RASTER)
        band = raster.GetRasterBand(1)  # nodata across top row

        values = coastal_vulnerability.extract_bathymetry_along_ray(
            all_valid_ray, geotransform, nodata_val, band)
        self.assertTrue(numpy.mean(values) == -1)

        values = coastal_vulnerability.extract_bathymetry_along_ray(
            some_nodata_ray, geotransform, nodata_val, band)
        self.assertTrue(numpy.mean(values) == -1)

        values = coastal_vulnerability.extract_bathymetry_along_ray(
            all_nodata_ray, geotransform, nodata_val, band)
        self.assertTrue(numpy.mean(values) == -1)

        with self.assertRaises(ValueError):
            values = coastal_vulnerability.extract_bathymetry_along_ray(
                out_of_bounds_ray, geotransform, nodata_val, band)

        nodata_band = raster.GetRasterBand(2)  # all nodata band
        with self.assertRaises(ValueError):
            values = coastal_vulnerability.extract_bathymetry_along_ray(
                all_valid_ray, geotransform, nodata_val, nodata_band)

        raster = None
        band = None
        nodata_band = None

    def test_wave_height_and_period(self):
        """CV: unit test for wave height and period equaitons."""
        # Testing with some reasonable values
        U = 15.0   # wind (meters / second)
        F = 10000  # fetch distance (meters)
        D = -20.0  # fetch depth (meters)
        height = coastal_vulnerability.compute_wave_height(U, F, D)
        period = coastal_vulnerability.compute_wave_period(U, F, D)
        numpy.testing.assert_almost_equal(height, 1.0260516)
        numpy.testing.assert_almost_equal(period, 3.6288811)

        # Test with U < 1 and expect U to be forced to 1.0
        F = 10000  # fetch distance (meters)
        D = -20.0  # fetch depth (meters)
        heightA = coastal_vulnerability.compute_wave_height(0.5, F, D)
        heightB = coastal_vulnerability.compute_wave_height(1.0, F, D)
        periodA = coastal_vulnerability.compute_wave_period(0.0, F, D)
        periodB = coastal_vulnerability.compute_wave_period(1.0, F, D)
        numpy.testing.assert_almost_equal(heightA, heightB)
        numpy.testing.assert_almost_equal(periodA, periodB)

    def test_habitat_rank(self):
        """CV: regression test for habitat ranks."""
        workspace_dir = self.workspace_dir
        base_shore_point_vector_path = os.path.join(
            INPUT_DATA, "wwiii_shore_points_5000m.gpkg")
        habitat_table_path = os.path.join(
            INPUT_DATA, "natural_habitats_wcvi.csv")
        target_habitat_protection_path = os.path.join(
            workspace_dir, 'habitat_protection.csv')
        file_suffix = ''

        task_graph = taskgraph.TaskGraph(
            os.path.join(workspace_dir, 'taskgraph_dir'), -1)

        task_list, pickle_list = coastal_vulnerability._schedule_habitat_tasks(
            base_shore_point_vector_path, habitat_table_path,
            workspace_dir, file_suffix, task_graph)

        coastal_vulnerability.calculate_habitat_rank(
            pickle_list, target_habitat_protection_path)

        expected_habitat_path = os.path.join(
            REGRESSION_DATA, 'expected_habitat_protection.csv')
        actual_values_df = pandas.read_csv(target_habitat_protection_path)
        expected_values_df = pandas.read_csv(expected_habitat_path)
        pandas.testing.assert_frame_equal(actual_values_df, expected_values_df)

    def test_invalid_habitats_outside_search_radius(self):
        """CV: test habitat search when no valid habitat within range."""
        workspace_dir = self.workspace_dir
        habitat_vector_path = os.path.join(workspace_dir, 'invalid_habitat.gpkg')
        _ = make_vector_of_invalid_geoms(habitat_vector_path)

        base_shore_point_vector_path = os.path.join(
            INPUT_DATA, "wwiii_shore_points_5000m.gpkg")
        search_radius = 1  # meter, we don't want to find any habitat.
        habitat_rank = 1
        habitat_id = 'foo'
        target_habitat_pickle_path = os.path.join(workspace_dir, 'target.pickle')

        coastal_vulnerability.search_for_habitat(
            base_shore_point_vector_path, search_radius, habitat_rank,
            habitat_id, habitat_vector_path, target_habitat_pickle_path)

        with open(target_habitat_pickle_path, 'rb') as file:
            result = pickle.load(file)
        # When no habitat is found near a point, it gets a protection rank of 5
        self.assertTrue(
            set(list(result[habitat_id].values())) == set([5]))

    def test_geomorphology_rank(self):
        """CV: regression test for geomorphology values."""
        workspace_dir = self.workspace_dir
        geomorphology_vector_path = os.path.join(
            INPUT_DATA, "geomorphology_few_ranks.shp")
        base_shore_point_vector_path = os.path.join(
            INPUT_DATA, "wwiii_shore_points_5000m.gpkg")
        target_pickle_path = os.path.join(
            workspace_dir, 'geomorphology.pickle')
        model_resolution = 5000

        coastal_vulnerability.calculate_geomorphology_exposure(
            geomorphology_vector_path, 3,
            base_shore_point_vector_path,
            model_resolution, target_pickle_path)

        expected_values_pickle_path = os.path.join(
            REGRESSION_DATA, 'expected_geomorphology.json')
        assert_pickled_arrays_almost_equal(
            target_pickle_path, expected_values_pickle_path)

    def test_creation_of_missing_geomorphology_dataset(self):
        """CV: test vector is created when some points are missing geomorph."""
        workspace_dir = self.workspace_dir
        geomorphology_vector_path = os.path.join(
            INPUT_DATA, "geomorphology_few_ranks.shp")
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N
        simple_points_path = os.path.join(self.workspace_dir, 'simple_points.gpkg')
        # create a point vector very far from any geomorphology segments:
        point = [Point(0.0, 0.0)]
        sampledata.create_vector_on_disk(
            point, srs.ExportToWkt(),
            filename=simple_points_path, vector_format='GPKG',
            fields={'shore_id': 'int'}, attributes=[{'shore_id': 0}])
        target_pickle_path = os.path.join(
            workspace_dir, 'geomorphology.pickle')
        model_resolution = 5  # makes for very small search radius

        coastal_vulnerability.calculate_geomorphology_exposure(
            geomorphology_vector_path, 3,
            simple_points_path,
            model_resolution, target_pickle_path)

        expected_file_path = os.path.join(
            os.path.dirname(target_pickle_path),
            "shore_points_missing_geomorphology.gpkg")
        vector = gdal.OpenEx(expected_file_path, gdal.OF_VECTOR)
        layer = vector.GetLayer()
        n_features = layer.GetFeatureCount()
        layer = None
        vector = None
        self.assertEqual(len(point), n_features)

    def test_surge_exposure_rank(self):
        """CV: regression test for surge exposure values."""
        workspace_dir = self.workspace_dir
        base_shore_point_vector_path = os.path.join(
            INPUT_DATA, "wwiii_shore_points_5000m.gpkg")
        shelf_contour_path = os.path.join(
            INPUT_DATA, 'continental_shelf_contour.gpkg')
        target_surge_pickle_path = os.path.join(
            workspace_dir, 'surge.pickle')
        coastal_vulnerability.calculate_surge_exposure(
            base_shore_point_vector_path, shelf_contour_path,
            target_surge_pickle_path)
        expected_raw_values_path = os.path.join(
            REGRESSION_DATA, 'expected_surge.json')

        assert_pickled_arrays_almost_equal(
            target_surge_pickle_path, expected_raw_values_path)

    def test_no_shelf_contour_near_aoi(self):
        """CV: test ValueError raised if shelf contour is too far from shore."""
        workspace_dir = self.workspace_dir
        base_shore_point_vector_path = os.path.join(
            INPUT_DATA, "wwiii_shore_points_5000m.gpkg")
        shore_info = pygeoprocessing.get_vector_info(
            base_shore_point_vector_path)
        bbox = shore_info['bounding_box']
        srs_wkt = shore_info['projection']

        shelf_contour_path = os.path.join(workspace_dir, 'surge.geojson')
        # Shelf line starts 2000km from bbox, further than the 1500km allowable
        line_a = LineString([
            (bbox[0] - 2e6, bbox[1] - 2e6),
            (bbox[0] - 2e6 - 100, bbox[1] - 2e6 - 100)])
        sampledata.create_vector_on_disk(
            [line_a], srs_wkt, filename=shelf_contour_path)

        target_surge_pickle_path = os.path.join(workspace_dir, 'surge.pickle')
        with self.assertRaises(ValueError) as cm:
            coastal_vulnerability.calculate_surge_exposure(
                base_shore_point_vector_path, shelf_contour_path,
                target_surge_pickle_path)
        actual_message = str(cm.exception)
        expected_message = 'No portion of the shelf contour line'
        self.assertTrue(expected_message in actual_message)

    def test_surge_multilinestring_geometry(self):
        """CV: test surge calculation with multipart geometry input."""
        workspace_dir = self.workspace_dir
        aoi_vector_path = os.path.join(
            INPUT_DATA, 'AOI_BarkClay.shp')
        aoi_info = pygeoprocessing.get_vector_info(aoi_vector_path)
        bbox = aoi_info['bounding_box']
        srs_wkt = aoi_info['projection']

        # Make a shore point in center of AOI bbox
        shore_point_path = os.path.join(workspace_dir, 'shore_point.shp')
        sampledata.create_vector_on_disk(
            [Point((bbox[0] + bbox[2]) / 2.0, (bbox[1] + bbox[3]) / 2.0)],
            srs_wkt, filename=shore_point_path,
            fields={'shore_id': 'int'}, attributes=[{'shore_id': 0}])

        # Make surge line as diagonal of AOI bounding box
        # And make it a multi-part geometry to test handling of that case.
        shelf_contour_path = os.path.join(workspace_dir, 'surge.geojson')
        line_a = LineString([(bbox[0], bbox[1]), (bbox[2], bbox[3])])
        line_b = LineString([(bbox[0], bbox[1]), (bbox[2], bbox[3])])
        sampledata.create_vector_on_disk(
            MultiLineString([line_a, line_b]),
            srs_wkt, filename=shelf_contour_path)

        target_surge_pickle_path = os.path.join(
            workspace_dir, 'surge.pickle')

        coastal_vulnerability.calculate_surge_exposure(
            shore_point_path, shelf_contour_path,
            target_surge_pickle_path)

        # shore point is at center of AOI bounding box
        # shelf contour is the diagonal of the bounding box
        # So, expected value for distance to shelf contour is 0.0
        with open(target_surge_pickle_path, 'rb') as file:
            expected_vals = pickle.load(file)
        self.assertTrue(expected_vals[0] == 0.0)

    def test_relief_values(self):
        """CV: regression test for aggregated relief values."""
        workspace_dir = self.workspace_dir
        base_shore_point_vector_path = os.path.join(
            INPUT_DATA, 'wwiii_shore_points_5000m.gpkg')
        dem_path = os.path.join(
            INPUT_DATA, 'dem_wgs84.tif')
        target_relief_pickle_path = os.path.join(
            workspace_dir, 'relief.pickle')
        dem_averaging_radius = 20000.0
        model_resolution = 5000.0
        file_suffix = ''

        coastal_vulnerability.calculate_relief_exposure(
            base_shore_point_vector_path, dem_path, dem_averaging_radius,
            model_resolution, workspace_dir, file_suffix,
            target_relief_pickle_path)

        expected_raw_values_path = os.path.join(
            REGRESSION_DATA, 'expected_relief.json')

        # I found minor gdal version differences produced slightly different
        # pixel values from gdal.Warp. So asserting exact values
        # from calculate_relief_exposure might fail depending on gdal version.
        # Rather than pin this test to a specific gdal version, I'm asserting
        # equal rank values after binning the raw values into 1-5 ranks.
        with open(target_relief_pickle_path, 'rb') as file:
            actual_values_dict = pickle.load(file)
        actual_rank_dict = coastal_vulnerability._bin_values_to_percentiles(
            actual_values_dict, invert_values=True)
        with open(expected_raw_values_path, 'r') as file:
            expected_values_dict = json.load(file)
        expected_rank_dict = coastal_vulnerability._bin_values_to_percentiles(
            expected_values_dict, invert_values=True)
        expected_rank_dict = {
            int(x[0]): int(x[1]) for x in expected_rank_dict.items()}
        # the dict items need sorting by FID to match the pre-sorted pickled items
        expected_ranks = [x[1] for x in sorted(expected_rank_dict.items())]

        numpy.testing.assert_array_equal(
            list(actual_rank_dict.values()), expected_ranks)

    def test_population_values(self):
        """CV: regression test for aggregated population density."""
        workspace_dir = self.workspace_dir
        base_shore_point_vector_path = os.path.join(
            INPUT_DATA, 'wwiii_shore_points_5000m.gpkg')
        population_path = os.path.join(
            INPUT_DATA, 'population.tif')
        target_population_pickle_path = os.path.join(
            workspace_dir, 'population.pickle')
        search_radius = 20000.0
        model_resolution = 5000.0
        file_suffix = ''

        coastal_vulnerability.aggregate_population_density(
            base_shore_point_vector_path, population_path, search_radius,
            model_resolution, workspace_dir, file_suffix,
            target_population_pickle_path)

        expected_raw_values_path = os.path.join(
            REGRESSION_DATA, 'expected_population.json')

        assert_pickled_arrays_almost_equal(
            target_population_pickle_path, expected_raw_values_path)

    def test_interpolate_slr(self):
        """CV: regression test for sea-level rise values.

        This tests an edge case where there is only one point in the
        SLR dataset, and it requires a coordinate transformation.
        """
        workspace_dir = self.workspace_dir
        base_shore_point_vector_path = os.path.join(
            INPUT_DATA, 'wwiii_shore_points_5000m.gpkg')

        # Make an SLR point vector
        slr_fieldname = 'Trend'
        slr_point_vector_path = os.path.join(workspace_dir, 'simple_points.shp')
        out_driver = ogr.GetDriverByName('ESRI Shapefile')
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(4326)
        shapely_feature = Point(-125.65, 49.0)
        out_vector = out_driver.CreateDataSource(slr_point_vector_path)
        layer_name = os.path.basename(os.path.splitext(slr_point_vector_path)[0])
        out_layer = out_vector.CreateLayer(layer_name, srs=srs)
        field_defn = ogr.FieldDefn(slr_fieldname, ogr.OFTReal)
        out_layer.CreateField(field_defn)
        layer_defn = out_layer.GetLayerDefn()
        new_feature = ogr.Feature(layer_defn)
        new_geometry = ogr.CreateGeometryFromWkb(shapely_feature.wkb)
        new_feature.SetGeometry(new_geometry)
        new_feature.SetField(slr_fieldname, 1.3)
        out_layer.CreateFeature(new_feature)
        out_layer = None
        out_vector = None

        target_pickle_path = os.path.join(
            workspace_dir, 'slr.pickle')
        coastal_vulnerability.interpolate_sealevelrise_points(
            base_shore_point_vector_path, slr_point_vector_path,
            slr_fieldname, target_pickle_path)

        expected_raw_values_path = os.path.join(
            REGRESSION_DATA, 'expected_slr.json')

        assert_pickled_arrays_almost_equal(
            target_pickle_path, expected_raw_values_path)

    def test_interpolate_slr_beyond_maxdistance(self):
        """CV: test sea-level rise returns nan beyond max search distance."""
        workspace_dir = self.workspace_dir

        # Make a shore point
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N
        shore_point_path = os.path.join(workspace_dir, 'shore_point.shp')
        sampledata.create_vector_on_disk(
            [Point(0., 0.)], srs.ExportToWkt(), filename=shore_point_path,
            fields={'shore_id': 'int'}, attributes=[{'shore_id': 0}])

        slr_point_vector_path = os.path.join(workspace_dir, 'slr_point.shp')
        slr_fieldname = 'Trend'
        shapely_point = Point(1e6, 1e6)  # very far from the shore point
        make_slr_vector(
            slr_point_vector_path, slr_fieldname, shapely_point, srs)

        target_pickle_path = os.path.join(
            workspace_dir, 'slr.pickle')
        coastal_vulnerability.interpolate_sealevelrise_points(
            shore_point_path, slr_point_vector_path,
            slr_fieldname, target_pickle_path)

        with open(target_pickle_path, 'rb') as file:
            actual_values = pickle.load(file)
        expected_values = numpy.array([numpy.nan])

        numpy.testing.assert_almost_equal(
            list(actual_values.values()), expected_values, decimal=4)

    def test_slr_missing_field(self):
        """CV: test KeyError raised if slr field is not present in vector."""
        workspace_dir = self.workspace_dir
        # Make a shore point
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N
        shore_point_path = os.path.join(workspace_dir, 'shore_point.shp')
        sampledata.create_vector_on_disk(
            [Point(0., 0.)], srs.ExportToWkt(), filename=shore_point_path,
            fields={'shore_id': 'int'}, attributes=[{'shore_id': 0}])

        slr_point_vector_path = os.path.join(workspace_dir, 'slr_point.shp')
        slr_fieldname = 'Trend'
        shapely_point = Point(1., 1.)
        make_slr_vector(
            slr_point_vector_path, slr_fieldname, shapely_point, srs)
        nonexistent_field = 'foo'

        with self.assertRaises(KeyError) as cm:
            coastal_vulnerability.interpolate_sealevelrise_points(
                shore_point_path, slr_point_vector_path,
                nonexistent_field, 'target.pickle')
        actual_message = str(cm.exception)
        expected_message = 'fieldname %s not found in' % nonexistent_field
        self.assertTrue(expected_message in actual_message)

    def test_long_aggregate_radius(self):
        """CV: handle an unreasonably long search radius in raster aggregation."""
        workspace_dir = self.workspace_dir
        raster_path = os.path.join(workspace_dir, 'simple_raster.tif')
        target_pickle_path = os.path.join(workspace_dir, 'target.pickle')
        sample_distance = 1.5

        # Make a simple raster
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N
        projection_wkt = srs.ExportToWkt()
        geotransform = [0, 0.5, 0.0, 0, 0.0, -0.5]
        n = 5
        nodata_val = -1
        gtiff_driver = gdal.GetDriverByName('GTiff')
        new_raster = gtiff_driver.Create(
            raster_path, n, n, 1, gdal.GDT_Int32, options=[
                'TILED=YES', 'BIGTIFF=YES', 'COMPRESS=LZW',
                'BLOCKXSIZE=16', 'BLOCKYSIZE=16'])
        new_raster.SetProjection(projection_wkt)
        new_raster.SetGeoTransform(geotransform)
        new_band = new_raster.GetRasterBand(1)
        array = numpy.array(range(n**2)).reshape((n, n))
        new_band.WriteArray(array)
        if nodata_val is not None:
            new_band.SetNoDataValue(nodata_val)
        new_raster.FlushCache()
        new_band = None
        new_raster = None

        # Make a vector proximate to the raster
        simple_points_path = os.path.join(workspace_dir, 'simple_points.shp')
        sampledata.create_vector_on_disk(
            [Point(0.1, -0.1),  # pixel (0,0): kernel origin out of bounds
             Point(1.25, -1.25),  # pixel (2,2): kernel origin & extent out of bounds
             Point(2.1, -2.1),  # pixel (4,4): kernel extent out of bounds
             ],
            srs.ExportToWkt(), filename=simple_points_path,
            fields={'shore_id': 'int'},
            attributes=[{'shore_id': 0}, {'shore_id': 1}, {'shore_id': 2}])

        coastal_vulnerability._aggregate_raster_values_in_radius(
            simple_points_path, raster_path, sample_distance,
            target_pickle_path, 'mean')

        with open(target_pickle_path, 'rb') as file:
            actual_values = pickle.load(file)

        expected_values = numpy.array([6.5454, 12.0, 17.4545])

        numpy.testing.assert_almost_equal(
            list(actual_values.values()), expected_values, decimal=4)

    def test_complete_run(self):
        """CV: regression test for a complete run with all optional arguments."""
        args = CoastalVulnerabilityTests.generate_base_args(self.workspace_dir)
        # these optional args aren't included in base_args:
        args['geomorphology_vector_path'] = os.path.join(
            INPUT_DATA, 'geomorphology_few_ranks.shp')
        args['geomorphology_fill_value'] = 3
        args['population_raster_path'] = os.path.join(
            INPUT_DATA, 'population.tif')
        args['population_radius'] = 16000
        args['slr_vector_path'] = os.path.join(
            INPUT_DATA, 'sea_level_rise.gpkg')
        args['slr_field'] = 'Trend'
        coastal_vulnerability.execute(args)

        actual_values_df = pandas.read_csv(
            os.path.join(args['workspace_dir'], 'coastal_exposure.csv'))
        expected_values_df = pandas.read_csv(
            os.path.join(REGRESSION_DATA, 'expected_coastal_exposure.csv'))
        pandas.testing.assert_frame_equal(
            actual_values_df, expected_values_df, check_dtype=False)

        # Also expect matching shore_id field in all tabular outputs:
        intermediate_csv = pandas.read_csv(
            os.path.join(
                args['workspace_dir'], 'intermediate/intermediate_exposure.csv'))
        habitat_csv = pandas.read_csv(
            os.path.join(
                args['workspace_dir'], 'intermediate/habitats/habitat_protection.csv'))
        pandas.testing.assert_series_equal(
            actual_values_df['shore_id'], intermediate_csv['shore_id'])
        pandas.testing.assert_series_equal(
            actual_values_df['shore_id'], habitat_csv['shore_id'])

    def test_final_risk_calc(self):
        """CV: regression test for the final risk score calculation."""
        workspace_dir = self.workspace_dir

        target_point_vector_path = os.path.join(
            workspace_dir, 'coastal_exposure.gpkg')
        target_point_csv_path = os.path.join(
            workspace_dir, 'coastal_exposure.csv')

        # Points with ranks for the final equation. Also includes a field
        # without the R_ prefix, which final equation should ignore.
        base_vector_path = os.path.join(REGRESSION_DATA, 'coastal_exposure.gpkg')

        # This input gets modified in place, so first copy to working dir
        # I'm using GPKG driver to copy because that driver may have problems
        # updating a file created by a different GPKG driver version, and the version
        # used is dependent on GDAL version. https://gdal.org/drivers/vector/gpkg.html
        base_shore_point_vector = ogr.Open(base_vector_path)
        gpkg_driver = ogr.GetDriverByName('GPKG')
        gpkg_driver.CopyDataSource(
            base_shore_point_vector, target_point_vector_path)

        coastal_vulnerability.calculate_final_risk(
            target_point_vector_path, target_point_csv_path)

        actual_values_df = pandas.read_csv(target_point_csv_path)
        expected_values_df = pandas.read_csv(
            os.path.join(REGRESSION_DATA, 'expected_final_risk.csv'))
        pandas.testing.assert_frame_equal(
            actual_values_df, expected_values_df, check_dtype=False)

    def test_geometric_mean_with_nan(self):
        """CV: test geometric mean function retuns `nan` with missing data."""
        array = numpy.array([1, 1, 1, 1, None], dtype=numpy.float)
        result = coastal_vulnerability._geometric_mean(array)
        self.assertTrue(numpy.isnan(result))

    def test_final_risk_calc_with_missing_data(self):
        """CV: test missing data at feature propogates to empty field in output."""
        target_vector_path = os.path.join(self.workspace_dir, 'target.gpkg')
        target_csv_path = os.path.join(self.workspace_dir, 'target.csv')

        # This gpkg has a feature with an empty field value for 'R_slr'
        # The function modifies the file in place, so copy to test workspace first.

        # I'm using GPKG driver to copy because that driver may have problems
        # updating a file created by a different GPKG driver version, and the version
        # used is dependent on GDAL version. https://gdal.org/drivers/vector/gpkg.html
        base_vector_path = os.path.join(REGRESSION_DATA, 'test_missing_values.gpkg')
        base_shore_point_vector = ogr.Open(base_vector_path)
        gpkg_driver = ogr.GetDriverByName('GPKG')
        gpkg_driver.CopyDataSource(
            base_shore_point_vector, target_vector_path)

        coastal_vulnerability.calculate_final_risk(
            target_vector_path, target_csv_path)
        actual_values_df = pandas.read_csv(target_csv_path)

        # These fields should have missing values after the final calculations
        na_cols = ['exposure', 'habitat_role', 'exposure_no_habitats']
        na_data = [numpy.nan] * 3
        expected_df = pandas.DataFrame([na_data], columns=na_cols)

        pandas.testing.assert_frame_equal(
            actual_values_df[na_cols], expected_df)

    def test_binning_with_missing_data(self):
        """CV: test binning continuous values to ranks, w/ missing values."""
        n = 50
        mask = [10, 20, 30, 40]
        keys = range(n)
        numpy.random.seed(0)
        values = numpy.random.uniform(0, 1, n)
        values[mask] = numpy.nan
        missing_values_dict = dict(zip(keys, values))

        ranks_dict = coastal_vulnerability._bin_values_to_percentiles(
            missing_values_dict)

        # with random uniform values, all 5 ranks should be present
        expected_ranks = set([1, 2, 3, 4, 5])
        self.assertTrue(expected_ranks.issubset(ranks_dict.values()))
        # and the masked indices should be nans
        self.assertTrue(
            all(numpy.isnan(numpy.array(list(ranks_dict.values()))[mask])))

    def test_nodata_raster_aggregation(self):
        """CV: test raster aggregation over entirely nodata returns nan."""
        workspace_dir = self.workspace_dir
        raster_path = os.path.join(workspace_dir, 'nodata_raster.tif')
        target_pickle_path = os.path.join(workspace_dir, 'target.pickle')
        sample_distance = 1.5

        # Make a simple raster filled with all nodata
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N
        projection_wkt = srs.ExportToWkt()
        geotransform = [0, 0.5, 0.0, 0, 0.0, -0.5]
        n = 5
        nodata_val = -1
        gtiff_driver = gdal.GetDriverByName('GTiff')
        new_raster = gtiff_driver.Create(
            raster_path, n, n, 1, gdal.GDT_Int32, options=[
                'TILED=YES', 'BIGTIFF=YES', 'COMPRESS=LZW',
                'BLOCKXSIZE=16', 'BLOCKYSIZE=16'])
        new_raster.SetProjection(projection_wkt)
        new_raster.SetGeoTransform(geotransform)
        new_band = new_raster.GetRasterBand(1)
        array = numpy.array([nodata_val] * n**2).reshape((n, n))
        new_band.WriteArray(array)
        if nodata_val is not None:
            new_band.SetNoDataValue(nodata_val)
        new_raster.FlushCache()
        new_band = None
        new_raster = None

        # Make a vector proximate to the raster
        simple_points_path = os.path.join(workspace_dir, 'simple_points.shp')
        sampledata.create_vector_on_disk(
            [Point(0., 0.)],
            srs.ExportToWkt(), filename=simple_points_path,
            fields={'shore_id': 'int'}, attributes=[{'shore_id': 0}])

        coastal_vulnerability._aggregate_raster_values_in_radius(
            simple_points_path, raster_path, sample_distance,
            target_pickle_path, 'density')

        with open(target_pickle_path, 'rb') as file:
            actual_values = pickle.load(file)

        expected_values = numpy.array([numpy.nan])
        numpy.testing.assert_almost_equal(
            list(actual_values.values()), expected_values, decimal=4)

    def test_positive_dem_with_nodata_floats(self):
        """CV: test coercing negative DEM values to zero.

        More specifically, test the edge case where the input values are
        floats and very large/small values that overflow an Int16.

        """
        n = 5
        nodata_val = -99999

        array = numpy.array(
            [nodata_val] * n**2, dtype=numpy.float32).reshape((n, n))

        pos_array = coastal_vulnerability.zero_negative_values(
            array, nodata_val)
        # It's all nodata going in, so should be all same nodata out.
        numpy.testing.assert_array_equal(array, pos_array)

    def test_dem_undefined_nodata(self):
        """CV: test coercing negative DEM values to zero, undefined nodata."""
        n = 5
        nodata_val = -99999

        array = numpy.array(
            [nodata_val] * n**2, dtype=numpy.float32).reshape((n, n))

        pos_array = coastal_vulnerability.zero_negative_values(
            array, None)
        # It's all negative going in, so should be all 0s out.
        numpy.testing.assert_array_equal(numpy.zeros_like(array), pos_array)

    def test_exception_from_validate_polyline(self):
        """CV: raise ValueError on incorrect geometry type during validation.

        shelf_contour_vector_path must be a line geometry, here it's a polygon.
        """
        gpkg_driver = ogr.GetDriverByName("GPKG")
        shelf_poly_path = os.path.join(self.workspace_dir, 'shelf_poly.gpkg')
        vector = gpkg_driver.CreateDataSource(shelf_poly_path)
        wgs84_srs = osr.SpatialReference()
        wgs84_srs.ImportFromEPSG(4326)
        vector.CreateLayer('layer', wgs84_srs, ogr.wkbPolygon)
        vector = None
        args = CoastalVulnerabilityTests.generate_base_args(self.workspace_dir)
        args['shelf_contour_vector_path'] = shelf_poly_path
        with self.assertRaises(ValueError):
            err_list = coastal_vulnerability.validate(args)
            for keys, err_strings in err_list:
                if 'Must be a polyline vector' in err_strings:
                    raise ValueError(err_list)

    def test_shore_points_on_single_polygon(self):
        """CV: test shore point creation with single polygon landmass."""
        args = CoastalVulnerabilityTests.generate_base_args(self.workspace_dir)
        aoi_path = os.path.join(self.workspace_dir, 'aoi.geojson')
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N
        wkt = srs.ExportToWkt()
        sampledata.create_vector_on_disk(
            [Polygon([(-200, -200), (200, -200), (200, 200), (-200, 200), (-200, -200)])],
            wkt, filename=aoi_path)

        landmass_path = os.path.join(
            self.workspace_dir, 'landmass.geojson')
        sampledata.create_vector_on_disk(
            [Polygon([(-100, -100), (100, -100), (100, 100), (-100, 100), (-100, -100)])],
            wkt, filename=landmass_path)

        args['aoi_vector_path'] = aoi_path
        args['landmass_vector_path'] = landmass_path
        args['model_resolution'] = 100

        polygon_pickle = os.path.join(
            self.workspace_dir, 'polygon.pickle')
        lines_pickle = os.path.join(
            self.workspace_dir, 'lines.pickle')
        lines_rtree = os.path.join(
            self.workspace_dir, 'rtree.dat')
        target_vector_path = os.path.join(
            self.workspace_dir, 'shore_points.gpkg')

        coastal_vulnerability.prepare_landmass_line_index(
            args['landmass_vector_path'], polygon_pickle,
            lines_pickle, lines_rtree)
        coastal_vulnerability.interpolate_shore_points(
            args['aoi_vector_path'], lines_pickle,
            args['model_resolution'], target_vector_path)

        vector = gdal.OpenEx(
            target_vector_path, gdal.OF_VECTOR | gdal.GA_ReadOnly)
        layer = vector.GetLayer()
        n_points = layer.GetFeatureCount()
        self.assertTrue(n_points == 8)

    def test_shore_points_on_multi_polygon(self):
        """CV: test shore point creation with multipolygon landmass."""
        workspace_dir = self.workspace_dir

        args = CoastalVulnerabilityTests.generate_base_args(workspace_dir)
        aoi_path = os.path.join(workspace_dir, 'aoi.geojson')
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N
        wkt = srs.ExportToWkt()
        sampledata.create_vector_on_disk(
            [Polygon([(-200, -200), (200, -200), (200, 200), (-200, 200), (-200, -200)])],
            wkt, filename=aoi_path)

        landmass_path = os.path.join(
            workspace_dir, 'landmass.geojson')
        poly_a = Polygon([(-200, -200), (-100, -200), (-100, -100), (-200, -100), (-200, -200)])
        poly_b = Polygon([(100, 100), (200, 100), (200, 200), (100, 200), (100, 100)])
        sampledata.create_vector_on_disk(
            [poly_a,
             poly_b,
             MultiPolygon([poly_a, poly_b])],
            wkt, filename=landmass_path)

        args['aoi_vector_path'] = aoi_path
        args['landmass_vector_path'] = landmass_path
        args['model_resolution'] = 100

        polygon_pickle = os.path.join(
            workspace_dir, 'polygon.pickle')
        lines_pickle = os.path.join(
            workspace_dir, 'lines.pickle')
        lines_rtree = os.path.join(
            workspace_dir, 'rtree.dat')
        target_vector_path = os.path.join(
            workspace_dir, 'shore_points.gpkg')

        coastal_vulnerability.prepare_landmass_line_index(
            args['landmass_vector_path'], polygon_pickle,
            lines_pickle, lines_rtree)
        coastal_vulnerability.interpolate_shore_points(
            args['aoi_vector_path'], lines_pickle,
            args['model_resolution'], target_vector_path)

        vector = gdal.OpenEx(
            target_vector_path, gdal.OF_VECTOR | gdal.GA_ReadOnly)
        layer = vector.GetLayer()
        n_points = layer.GetFeatureCount()
        self.assertTrue(n_points == 8)

    def test_zero_shorepoints_created(self):
        """CV: test RuntimeError raised if zero shore points are created."""
        args = CoastalVulnerabilityTests.generate_base_args(self.workspace_dir)
        aoi_path = os.path.join(self.workspace_dir, 'aoi.geojson')
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N
        wkt = srs.ExportToWkt()
        a = 100
        sampledata.create_vector_on_disk(
            [Polygon([(-a, -a), (a, -a), (a, a), (-a, a), (-a, -a)])],
            wkt, filename=aoi_path)

        landmass_path = os.path.join(self.workspace_dir, 'landmass.geojson')
        # This lanmass fully encloses the AOI, but has no edges within the AOI.
        # Such a landmass would pass validation's spatial overlap check.
        b = a * 2
        sampledata.create_vector_on_disk(
            [Polygon([(-b, -b), (b, -b), (b, b), (-b, b), (-b, -b)])],
            wkt, filename=landmass_path)

        args['aoi_vector_path'] = aoi_path
        args['landmass_vector_path'] = landmass_path
        args['model_resolution'] = 5

        polygon_pickle = os.path.join(
            self.workspace_dir, 'polygon.pickle')
        lines_pickle = os.path.join(
            self.workspace_dir, 'lines.pickle')
        lines_rtree = os.path.join(
            self.workspace_dir, 'rtree.dat')
        target_vector_path = os.path.join(
            self.workspace_dir, 'shore_points.gpkg')

        coastal_vulnerability.prepare_landmass_line_index(
            args['landmass_vector_path'], polygon_pickle,
            lines_pickle, lines_rtree)

        with self.assertRaises(RuntimeError):
            coastal_vulnerability.interpolate_shore_points(
                args['aoi_vector_path'], lines_pickle,
                args['model_resolution'], target_vector_path)

    def test_aoi_multiple_features(self):
        """CV: test shore point creation in AOI with multiple features."""
        workspace_dir = self.workspace_dir

        args = CoastalVulnerabilityTests.generate_base_args(workspace_dir)
        aoi_path = os.path.join(workspace_dir, 'aoi.geojson')
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N
        wkt = srs.ExportToWkt()
        poly_a = Polygon([(-200, -200), (-100, -200), (-100, -100), (-200, -100), (-200, -200)])
        poly_b = Polygon([(100, 100), (200, 100), (200, 200), (100, 200), (100, 100)])
        sampledata.create_vector_on_disk(
            [poly_a, poly_b],
            wkt, filename=aoi_path)

        landmass_path = os.path.join(
            workspace_dir, 'landmass.geojson')
        sampledata.create_vector_on_disk(
            [Polygon([(-190, -190), (190, -190), (190, 190), (-190, 190), (-190, -190)])],
            wkt, filename=landmass_path)

        args['aoi_vector_path'] = aoi_path
        args['landmass_vector_path'] = landmass_path
        args['model_resolution'] = 80

        polygon_pickle = os.path.join(
            workspace_dir, 'polygon.pickle')
        lines_pickle = os.path.join(
            workspace_dir, 'lines.pickle')
        lines_rtree = os.path.join(
            workspace_dir, 'rtree.dat')
        target_vector_path = os.path.join(
            workspace_dir, 'shore_points.gpkg')

        coastal_vulnerability.prepare_landmass_line_index(
            args['landmass_vector_path'], polygon_pickle,
            lines_pickle, lines_rtree)
        coastal_vulnerability.interpolate_shore_points(
            args['aoi_vector_path'], lines_pickle,
            args['model_resolution'], target_vector_path)

        vector = gdal.OpenEx(
            target_vector_path, gdal.OF_VECTOR | gdal.GA_ReadOnly)
        layer = vector.GetLayer()
        n_points = layer.GetFeatureCount()
        self.assertTrue(n_points == 6)

    def test_no_wwiii_coverage(self):
        """CV: test exception when shore points are outside max wwiii distance."""
        args = CoastalVulnerabilityTests.generate_base_args(self.workspace_dir)
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N

        simple_points_path = os.path.join(self.workspace_dir, 'simple_points.shp')
        sampledata.create_vector_on_disk(
            [Point(0.0, 0.0)],
            srs.ExportToWkt(), filename=simple_points_path,
            fields={'shore_id': 'int'}, attributes=[{'shore_id': 0}])

        target_path = os.path.join(self.workspace_dir, 'target.gpkg')
        with self.assertRaises(ValueError):
            coastal_vulnerability.interpolate_wwiii_to_shore(
                simple_points_path, args['wwiii_vector_path'],
                target_path)

    def test_projected_wwiii_input(self):
        """CV: test wwiii interpolation with a projected wwiii input vector."""
        workspace_dir = self.workspace_dir
        args = CoastalVulnerabilityTests.generate_base_args(workspace_dir)
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N

        projected_wwiii_vector_path = os.path.join(
            workspace_dir, 'prj_wwiii.shp')
        pygeoprocessing.reproject_vector(
            args['wwiii_vector_path'], srs.ExportToWkt(),
            projected_wwiii_vector_path)

        bbox = pygeoprocessing.get_vector_info(
            projected_wwiii_vector_path)['bounding_box']
        simple_points_path = os.path.join(workspace_dir, 'simple_points.shp')
        sampledata.create_vector_on_disk(
            [Point((bbox[0] + bbox[2]) / 2.0, (bbox[1] + bbox[3]) / 2.0)],
            srs.ExportToWkt(), filename=simple_points_path,
            fields={'shore_id': 'int'}, attributes=[{'shore_id': 0}])

        target_path = os.path.join(workspace_dir, 'target.gpkg')
        coastal_vulnerability.interpolate_wwiii_to_shore(
            simple_points_path, projected_wwiii_vector_path,
            target_path)

        vector = gdal.OpenEx(target_path, gdal.OF_VECTOR | gdal.GA_ReadOnly)
        layer = vector.GetLayer()
        layer_defn = layer.GetLayerDefn()
        n_fields = layer_defn.GetFieldCount()
        self.assertTrue(n_fields == 126)

        # Just spot-checking one field here. Overall correctness is verified by
        # other regression tests.
        feature = layer.GetFeature(1)  # gpkg FID index = 1
        value = feature.GetField('REI_PCT90')
        self.assertTrue(numpy.isclose(value, 0.0146246))

        feature = None
        layer_defn = None
        layer = None
        vector = None

    def test_prepare_landmass_invalid_geometry(self):
        """CV: test handling invalid geometries in landmass vector."""
        landmass_vector_path = os.path.join(self.workspace_dir, 'vector.gpkg')
        n_features = make_vector_of_invalid_geoms(landmass_vector_path)

        target_polygon_pickle_path = os.path.join(
            self.workspace_dir, 'polygon.pickle')
        target_lines_pickle_path = os.path.join(
            self.workspace_dir, 'lines.pickle')
        target_rtree_path = os.path.join(self.workspace_dir, 'rtree.dat')
        # Create rtree files to exercise the function's logic of removing
        # pre-exisiting files
        target_rtree_path_base = os.path.splitext(target_rtree_path)[0]
        open(target_rtree_path, 'a').close()
        open(target_rtree_path_base + '.idx', 'a').close()
        coastal_vulnerability.prepare_landmass_line_index(
            landmass_vector_path, target_polygon_pickle_path,
            target_lines_pickle_path, target_rtree_path)

        with open(target_polygon_pickle_path, 'rb') as polygon_file:
            shapely_geom_list = pickle.load(polygon_file)

        # Expect 1 input geometry to be skipped, and the rest to be in
        # shapely_geom_list.
        self.assertTrue(len(shapely_geom_list) == n_features - 1)

    def test_clip_project_already_projected_raster(self):
        """CV: test clip_and_project_raster on an already projected raster."""
        workspace_dir = self.workspace_dir
        base_raster_path = os.path.join(workspace_dir, 'nodata_raster.tif')
        target_raster_path = os.path.join(workspace_dir, 'target.tiff')

        # Make a simple raster in a projected SRS
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(26910)  # UTM Zone 10N
        projection_wkt = srs.ExportToWkt()
        geotransform = [0, 0.5, 0.0, 0, 0.0, -0.5]
        n = 5
        nodata_val = -1
        gtiff_driver = gdal.GetDriverByName('GTiff')
        new_raster = gtiff_driver.Create(
            base_raster_path, n, n, 1, gdal.GDT_Int32, options=[
                'TILED=YES', 'BIGTIFF=YES', 'COMPRESS=LZW',
                'BLOCKXSIZE=16', 'BLOCKYSIZE=16'])
        new_raster.SetProjection(projection_wkt)
        new_raster.SetGeoTransform(geotransform)
        new_band = new_raster.GetRasterBand(1)
        array = numpy.array([nodata_val] * n**2).reshape((n, n))
        new_band.WriteArray(array)
        if nodata_val is not None:
            new_band.SetNoDataValue(nodata_val)
        new_raster.FlushCache()
        new_band = None
        new_raster = None

        raster_info = pygeoprocessing.get_raster_info(base_raster_path)
        clipping_box = raster_info['bounding_box']
        target_srs_wkt = raster_info['projection']
        model_resolution = 9  # expect this to be ignored
        file_suffix = ''

        coastal_vulnerability.clip_and_project_raster(
            base_raster_path, clipping_box, target_srs_wkt, model_resolution,
            workspace_dir, file_suffix, target_raster_path)

        # If the input was unprojected, the output pixel size would be the
        # model_resolution. Instead, here we expect pixel_size to remain the
        # same as the original base raster.
        actual_pixel_size = pygeoprocessing.get_raster_info(
            target_raster_path)['pixel_size']
        self.assertTrue(
            actual_pixel_size == (geotransform[1], geotransform[5]))

    def test_clip_project_vector_on_invalid_geometry(self):
        """CV: test clip and project vector on input with invalid geometry."""
        workspace_dir = self.workspace_dir
        base_vector_path = os.path.join(workspace_dir, 'invalid.gpkg')
        n_features = make_vector_of_invalid_geoms(base_vector_path)
        vector_info = pygeoprocessing.get_vector_info(base_vector_path)
        clipping_box = vector_info['bounding_box']
        target_srs_wkt = vector_info['projection']
        tmp_vector_path = 'tmp_clipped.gpkg'
        target_vector_path = 'clipped_projected.gpkg'

        coastal_vulnerability.clip_and_project_vector(
            base_vector_path, clipping_box, target_srs_wkt,
            tmp_vector_path, target_vector_path)

        # One of the invalid geometries cannot be loaded by shapely
        # and will be skipped, so expect the target to have one fewer
        # feature than the base.
        target_vector = gdal.OpenEx(
            target_vector_path, gdal.OF_VECTOR | gdal.GA_ReadOnly)
        target_layer = target_vector.GetLayer()
        n_actual_features = target_layer.GetFeatureCount()
        self.assertTrue(n_actual_features == n_features - 1)

    def test_invalid_raster_aggregation_mode(self):
        """CV: test ValueError raised on invalid raster aggration mode."""
        base_point_vector_path = 'base.gpkg'
        base_raster_path = 'base.tif'
        sample_distance = 3
        target_pickle_path = os.path.join(self.workspace_dir, 'some.pickle')
        aggregation_mode = 'foo'

        with self.assertRaises(ValueError) as cm:
            coastal_vulnerability._aggregate_raster_values_in_radius(
                base_point_vector_path, base_raster_path, sample_distance,
                target_pickle_path, aggregation_mode)
        actual_message = str(cm.exception)
        expected_message = 'aggregation mode must be either "mean" or "density"'
        self.assertTrue(actual_message == expected_message)

    def test_invalid_habitat_table_paths(self):
        """CV: test ValueError raised on invalid filepaths inside table."""
        habitat_table_path = os.path.join(self.workspace_dir, 'bad_table.csv')
        df = pandas.DataFrame(
            columns=['id', 'path', 'rank', 'protection distance (m)'],
            data=[['foo', 'bad_path.shp', 3, 400]])
        df.to_csv(habitat_table_path)
        with self.assertRaises(ValueError) as cm:
            coastal_vulnerability._validate_habitat_table_paths(
                habitat_table_path)
        actual_message = str(cm.exception)
        expected_message = 'Could not open these vectors referenced in'
        self.assertTrue(expected_message in actual_message)

    def test_polygon_to_lines(self):
        """CV: test a helper function that converts polygons to linestrings."""
        # Test a polygon with inner rings to cover all paths through function.
        donut_wkt = 'POLYGON ((35 10, 45 45, 15 40, 10 20, 35 10), (20 30, 35 35, 30 20, 20 30))'
        geometry = ogr.CreateGeometryFromWkt(donut_wkt)
        shapely_geom = shapely.wkb.loads(geometry.ExportToWkb())
        line_list = coastal_vulnerability.polygon_to_lines(shapely_geom)
        # Polygon has 4 sides on exterior, 3 on interior, expect 7 lines
        self.assertTrue(len(line_list) == 7)


def assert_pickled_arrays_almost_equal(
        actual_values_pickle_path, expected_values_json_path):
    """Open a pickled dict and assert keys and values match expected.

    Expected data is stored in json as pickles are really only reliably
    read by the same program that wrote them.
    """
    with open(actual_values_pickle_path, 'rb') as pickle_file:
        actual_values_dict = pickle.load(pickle_file)
    actual_values = list(actual_values_dict.values())
    actual_fids = list(actual_values_dict.keys())

    with open(expected_values_json_path, 'r') as json_file:
        expected_values_dict = json.load(json_file)
    expected_values_dict = {
        int(x[0]): float(x[1]) for x in expected_values_dict.items()}
    # the dict items need sorting by FID to match the pre-sorted pickled items
    expected_fids = [x[0] for x in sorted(expected_values_dict.items())]
    expected_values = [x[1] for x in sorted(expected_values_dict.items())]

    numpy.testing.assert_array_almost_equal(
        actual_values, expected_values, decimal=2)
    numpy.testing.assert_array_equal(actual_fids, expected_fids)


class CoastalVulnerabilityValidationTests(unittest.TestCase):
    """Tests for the CV Model ARGS_SPEC and validation."""
    def setUp(self):
        """Create a temporary workspace."""
        self.workspace_dir = tempfile.mkdtemp()
        self.base_required_keys = [
            'workspace_dir',
            'aoi_vector_path',
            'model_resolution',
            'landmass_vector_path',
            'wwiii_vector_path',
            'max_fetch_distance',
            'bathymetry_raster_path',
            'shelf_contour_vector_path',
            'dem_path',
            'dem_averaging_radius',
            'habitat_table_path',
        ]

    def tearDown(self):
        """Remove the temporary workspace after a test."""
        shutil.rmtree(self.workspace_dir)

    def test_missing_keys(self):
        """CV Validate: assert missing required keys."""
        from natcap.invest import coastal_vulnerability
        from natcap.invest import validation

        validation_errors = coastal_vulnerability.validate({})  # empty args dict.
        invalid_keys = validation.get_invalid_keys(validation_errors)
        expected_missing_keys = set(
            self.base_required_keys)
        self.assertEqual(invalid_keys, expected_missing_keys)

    def test_missing_keys_geomorphology(self):
        """CV Validate: assert missing geomorphology keys."""
        from natcap.invest import coastal_vulnerability
        from natcap.invest import validation

        args = {'geomorphology_vector_path': 'foo.shp'}
        validation_errors = coastal_vulnerability.validate(args)
        invalid_keys = validation.get_invalid_keys(validation_errors)
        expected_missing_keys = set(
            self.base_required_keys +
            ['geomorphology_fill_value',
             'geomorphology_vector_path'])
        self.assertEqual(invalid_keys, expected_missing_keys)

    def test_missing_keys_population(self):
        """CV Validate: assert missing population keys."""
        from natcap.invest import coastal_vulnerability
        from natcap.invest import validation

        args = {'population_raster_path': 'foo.tif'}
        validation_errors = coastal_vulnerability.validate(args)
        invalid_keys = validation.get_invalid_keys(validation_errors)
        expected_missing_keys = set(
            self.base_required_keys +
            ['population_raster_path',
             'population_radius'])
        self.assertEqual(invalid_keys, expected_missing_keys)

    def test_missing_keys_sealevelrise(self):
        """CV Validate: assert missing sealevelrise keys."""
        from natcap.invest import coastal_vulnerability
        from natcap.invest import validation

        args = {'slr_vector_path': 'foo.shp'}
        validation_errors = coastal_vulnerability.validate(args)
        invalid_keys = validation.get_invalid_keys(validation_errors)
        expected_missing_keys = set(
            self.base_required_keys +
            ['slr_vector_path',
             'slr_field'])
        self.assertEqual(invalid_keys, expected_missing_keys)

    def test_message_about_incorrect_geometry(self):
        """CV Validate: test catching incorrect shelf contour geometry type.

        shelf_contour_vector_path must be a line geometry, here it's a polygon.
        """
        gpkg_driver = ogr.GetDriverByName("GPKG")
        shelf_poly_path = os.path.join(self.workspace_dir, 'shelf_poly.gpkg')
        vector = gpkg_driver.CreateDataSource(shelf_poly_path)
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(4326)
        vector.CreateLayer('layer', srs, ogr.wkbPolygon)
        vector = None
        with self.assertRaises(ValueError):
            err_list = coastal_vulnerability.validate(
                {'shelf_contour_vector_path': shelf_poly_path})
            for keys, err_strings in err_list:
                if 'Must be a polyline vector' in err_strings:
                    raise ValueError(err_list)

    def test_missing_sealevelrise_field(self):
        """CV Validate: test catching SLR field not present in vector."""
        slr_vector_path = os.path.join(
            INPUT_DATA, 'sea_level_rise.gpkg')
        with self.assertRaises(ValueError):
            err_list = coastal_vulnerability.validate(
                {'slr_vector_path': slr_vector_path,
                 'slr_field': 'foo'})
            for keys, err_strings in err_list:
                if 'Value must be one of:' in err_strings:
                    raise ValueError(err_strings)


def make_slr_vector(slr_point_vector_path, fieldname, shapely_feature, srs):
    """Create an SLR vector with a single point feature.

    Args:
        slr_point_vector_path (string): path to the target vector
        fieldname (string): name of a field to be created in target vector
        shapely_feautre (Point): shapely Point object
        srs (osr.SpatialReference)

    Returns:
        None

    """
    driver = ogr.GetDriverByName('ESRI Shapefile')
    out_vector = driver.CreateDataSource(slr_point_vector_path)
    layer_name = os.path.basename(os.path.splitext(slr_point_vector_path)[0])
    out_layer = out_vector.CreateLayer(layer_name, srs=srs)
    field_defn = ogr.FieldDefn(fieldname, ogr.OFTReal)
    out_layer.CreateField(field_defn)
    layer_defn = out_layer.GetLayerDefn()
    new_feature = ogr.Feature(layer_defn)
    new_geometry = ogr.CreateGeometryFromWkb(shapely_feature.wkb)
    new_feature.SetGeometry(new_geometry)
    new_feature.SetField(fieldname, 1.3)  # any value will do
    out_layer.CreateFeature(new_feature)
    out_layer = None
    out_vector = None


def make_vector_of_invalid_geoms(target_vector_path):
    """Make features out of various invalid geometries.

    Most example geometries come from: https://github.com/tudelft3d/prepair
    Three of the geomtries below can be fixed with a 0-width buffer.
    One geometry below cannot be loaded by shapely or fixed by a buffer.
    I don't have an example that CAN be loaded by shapely, but CANNOT be
    fixed by the buffer.

    Make these geometries non-overlapping because some of the CV functions
    being tested with these do a cascaded union. Isolating the geometries
    makes it possible to assert that the number of geometries going in equals
    the number of features coming out, regardless of that union.

    Returns:
        Integer representing the number of features created

    """
    # 1: Bowtie polygon - fixed by buffer
    invalid_bowtie_polygon = ogr.CreateGeometryFromWkt(
        'POLYGON ((-20 -20, -16 -20, -20 -16, -16 -16, -20 -20))')
    assert not invalid_bowtie_polygon.IsValid()

    # 2: Inner ring with one edge sharing part of an edge of the outer ring
    #  - fixed by buffer
    invalid_shared_edge_polygon = ogr.CreateGeometryFromWkt(
        'POLYGON((0 0, 10 0, 10 10, 0 10, 0 0),(5 2,5 7,10 7, 10 2, 5 2))')
    assert not invalid_shared_edge_polygon.IsValid()

    # 3: Dangling edge - fixed by buffer
    invalid_dangling_edge_polygon = ogr.CreateGeometryFromWkt(
        'POLYGON((100 100, 110 100, 115 105, 110 100, 110 110, 100 110, 100 100))')
    assert not invalid_dangling_edge_polygon.IsValid()

    # One invalid geom that cannot be loaded by shapely or fixed by buffer
    # We expect this polygon to be skipped by the CV functions being tested.
    # 4: invalid open ring polygon
    invalid_open_ring_polygon = ogr.CreateGeometryFromWkt(
        'POLYGON ((2 -2, 6 -2, 6 -6, 2 -6))')
    assert not invalid_open_ring_polygon.IsValid()

    gpkg_driver = gdal.GetDriverByName('GPKG')
    srs = osr.SpatialReference()
    srs.ImportFromEPSG(32731)  # WGS84/UTM zone 31s
    target_vector = gpkg_driver.Create(
        target_vector_path, 0, 0, 0, gdal.GDT_Unknown)
    target_layer = target_vector.CreateLayer(
        'target_layer', srs, ogr.wkbUnknown)

    target_layer.StartTransaction()
    input_geom_list = [invalid_bowtie_polygon,
                       invalid_shared_edge_polygon,
                       invalid_dangling_edge_polygon,
                       invalid_open_ring_polygon]
    for geometry in input_geom_list:
        outflow_feature = ogr.Feature(target_layer.GetLayerDefn())
        outflow_feature.SetGeometry(geometry)
        target_layer.CreateFeature(outflow_feature)
    target_layer.CommitTransaction()

    target_layer = None
    target_vector = None

    return len(input_geom_list)
